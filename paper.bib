
@InProceedings{Arthur1997b,
  author = 	 {W.~B. Arthur and J. H. Holland and R. Palmer and P. Tayler},
  title = 	 {Asset Pricing Under Endogenous Expectations in an Artificial Stock Market},
  booktitle = {The Economy as an Evolving Complex System II},
  year = 	 1997,
  editor = 	 {W. B. Arthur and S. Durlauf and D. Lane},
  publisher = {Addison-Wesley}}

@article{Arthur1997a,
abstract = {We propose a theory of asset pricing based on heterogeneous agents who continually adapt their expectations to the market that these expectations aggregatively create. And we explore the implications of this theory computationally using our Santa Fe artificial stock market. Asset markets, we argue, have a recursive nature in that agents' expectations are formed on the basis of their anticipations of other agents' expectations, which precludes expectations being formed by deductive means. Instead traders continually hypothesize-continually explore-expectational models, buy or sell on the basis of those that perform best, and confirm or discard these according to their performance. Thus individual beliefs or expectations become endogenous to the market, and constantly compete within an ecology of others' beliefs or expectations. The ecology of beliefs co-evolves over time. Computer experiments with this endogenous-expectations market explain one of the more striking puzzles in finance: that market traders often believe in such concepts as technical trading, market psychology, and bandwagon effects, while academic theorists believe in market efficiency and a lack of speculative opportunities. Both views, we show, are correct, but within different regimes. Within a regime where investors explore alternative expectational models at a low rate, the market settles into the rational-expectations equilibrium of the efficient-market literature. Within a regime where the rate of exploration of alternative expectations is higher, the market self-organizes into a complex pattern. It acquires a rich psychology, technical trading emerges, temporary bubbles and crashes occur, and asset prices and trading volume show statistical features-in particular, GARCH behavior-characteristic of actual market data.},
author = {Arthur, W. B. and Holland, J. H. and LeBaron, B. D. and Palmer, R. G. and Tayler, P.},
doi = {10.2139/ssrn.2252},
issn = {1556-5068},
journal = {SSRN Electronic Journal},
month = dec,
title = {{Asset pricing under endogenous expectations in an artificial stock market}},
url = {http://papers.ssrn.com/abstract=2252},
year = {1997}
}
@book{Ashby1956,
address = {London},
author = {Ashby, W. R.},
publisher = {Chapman \& Hall},
title = {{An Introduction to Cybernetics}},
year = {1956}
}
@book{Bellman1961,
abstract = {The Description for this book, Adaptive Control Processes: A Guided Tour, will be forthcoming.},
author = {Bellman, R. E.},
publisher = {Princeton University Press},
title = {{Adaptive Control Processes: A Guided Tour}},
url = {https://books.google.com/books/about/Adaptive\_Control\_Processes.html?id=POAmAAAAMAAJ\&pgis=1},
year = {1961}
}
@article{Booker1989,
abstract = {Classifier systems are massively parallel, message-passing, rule-based systems that learn through credit assignment (the bucket brigade algorithm) and rule discovery (the genetic algorithm). They typically operate in environments that exhibit one or more of the following characteristics: (1) perpetually novel events accompanied by large amounts of noisy or irrelevant data; (2) continual, often real-time, requirements for action; (3) implicitly or inexactly defined goals; and (4) sparse payoff or reinforcement obtainable only through long action sequences. Classifier systems are designed to absorb new information continuously from such environments, devising sets of competing hypotheses (expressed as rules) without disturbing significantly capabilities already acquired. This paper reviews the definition, theory, and extant applications of classifier systems, comparing them with other machine learning techniques, and closing with a discussion of advantages, problems, and possible extensions of classifier systems.},
author = {Booker, L. B. and Goldberg, D. E. and Holland, J. H.},
doi = {10.1016/0004-3702(89)90050-7},
issn = {00043702},
journal = {Artificial Intelligence},
month = sep,
number = {1-3},
pages = {235--282},
title = {{Classifier systems and genetic algorithms}},
url = {http://www.sciencedirect.com/science/article/pii/0004370289900507},
volume = {40},
year = {1989}
}
@article{Christiansen1998,
author = {Christiansen, F. B. and Feldman, M. W.},
doi = {10.1002/(SICI)1099-0526(199801/02)3:3<57::AID-CPLX9>3.0.CO;2-J},
issn = {1076-2787},
journal = {Complexity},
month = jan,
number = {3},
pages = {57--64},
title = {{Algorithms, genetics, and populations: The schemata theorem revisited}},
url = {http://doi.wiley.com/10.1002/\%28SICI\%291099-0526\%28199801/02\%293\%3A3\%3C57\%3A\%3AAID-CPLX9\%3E3.0.CO\%3B2-J},
volume = {3},
year = {1998}
}
@book{Dennett1984,
abstract = {In this landmark 1984 work on free will, Daniel Dennett makes a case for compatibilism. His aim, as he writes in the preface to this new edition, was a cleanup job, "saving everything that mattered about the everyday concept of free will, while jettisoning the impediments." In Elbow Room, Dennett argues that the varieties of free will worth wanting -- those that underwrite moral and artistic responsibility -- are not threatened by advances in science but distinguished, explained, and justified in detail.Dennett tackles the question of free will in a highly original and witty manner, drawing on the theories and concepts of fields that range from physics and evolutionary biology to engineering, automata theory, and artificial intelligence. He shows how the classical formulations of the problem in philosophy depend on misuses of imagination, and he disentangles the philosophical problems of real interest from the "family of anxieties" in which they are often enmeshed -- imaginary agents and bogeymen, including the Peremptory Puppeteer, the Nefarious Neurosurgeon, and the Cosmic Child Whose Dolls We Are. Putting sociobiology in its rightful place, he concludes that we can have free will and science too. He explores reason, control and self-control, the meaning of "can" and "could have done otherwise," responsibility and punishment, and why we would want free will in the first place. A fresh reading of Dennett's book shows how much it can still contribute to current discussions of free will. This edition includes as its afterword Dennett's 2012 Erasmus Prize essay.},
author = {Dennett, D. C.},
isbn = {0262332043},
publisher = {MIT Press},
title = {{Elbow Room: The Varieties of Free Will Worth Wanting}},
url = {https://books.google.com/books?id=PN1dCgAAQBAJ\&pgis=1},
year = {1984}
}
@book{Eddington1927,
address = {Cambridge, UK},
author = {Eddington, A.},
publisher = {Cambridge University Press},
title = {{The Nature of the Physical World: Gifford Lectures, 1927}},
year = {1927}
}
@book{Fisher1930,
abstract = {R A Fisher's classic The Genetical Theory of Natural Selection was first published by the Oxford University Press in 1930. It was the first attempt to assess and explain Darwin's evolutionary theories in terms of the genetic processes underlying them, and was also original in being the first book to establish a firm theoretical basis for evolution. Since then, it has become a classic text in evolutionary biology, with Fisher hailed as one of the greatest evolutionary biologists of this century. This Variorum edition will be the definitive version - the only version of The Genetical Theory in print: it will include both Fisher's original 1930 text and that of a second edition of the book, published by Dover publications in 1958, which is now out of print. It also has a new Foreword, some unpublished material by Fisher that he wrote in his own copy, and letters between Fisher and Darwin's grandson, Leonard Darwin. Students, researchers, and general readers with an interest in the history of evolutionary biology will welcome this new edition.},
author = {Fisher, R. A.},
isbn = {0198504403},
pages = {318},
publisher = {OUP Oxford},
title = {{The Genetical Theory of Natural Selection: A Complete Variorum Edition}},
url = {https://books.google.com/books?hl=en\&lr=\&id=sT4lIDk5no4C\&pgis=1},
year = {1930}
}
@phdthesis{Goldberg1983,
author = {Goldberg, D. E.},
keywords = {\& storage,handling,natural gas 032000*  -- natural gas-- transport},
language = {English},
month = jan,
publisher = {Univ. of Michigan,Ann Arbor, MI, USA},
school = {University of Michigan},
title = {{Computer-Aided Gas Pipeline Operation Using Genetic Algorithms and Rule Learning}},
url = {http://www.osti.gov/scitech/biblio/6272747},
year = {1983}
}
@book{Holland2014,
abstract = {The importance of complexity is well-captured by Hawking's comment: "Complexity is the science of the 21st century". From the movement of flocks of birds to the Internet, environmental sustainability, and market regulation, the study and understanding of complex non-linear systems has become highly influential over the last 30 years. In this Very Short Introduction, one of the leading figures in the field, John Holland, introduces the key elements and conceptual framework of complexity. From complex physical systems such as fluid flow and the difficulties of predicting weather, to complex adaptive systems such as the highly diverse and interdependent ecosystems of rainforests, he combines simple, well-known examples -- Adam Smith's pin factory, Darwin's comet orchid, and Simon's 'watchmaker' -- with an account of the approaches, involving agents and urn models, taken by complexity theory. ABOUT THE SERIES: The Very Short Introductions series from Oxford University Press contains hundreds of titles in almost every subject area. These pocket-sized books are the perfect way to get ahead in a new subject quickly. Our expert authors combine facts, analysis, perspective, new ideas, and enthusiasm to make interesting and challenging topics highly readable.},
author = {Holland, J. H.},
isbn = {0199662541},
pages = {95},
publisher = {Oxford University Press},
title = {{Complexity: A Very Short Introduction}},
url = {https://books.google.com/books?id=lmygAwAAQBAJ\&pgis=1},
year = {2014}
}
@book{Holland2012,
abstract = {Complex adaptive systems (cas), including ecosystems, governments, biological cells, and markets, are characterized by intricate hierarchical arrangements of boundaries and signals. In ecosystems, for example, niches act as semi-permeable boundaries, and smells and visual patterns serve as signals; governments have departmental hierarchies with memoranda acting as signals; and so it is with other cas. Despite a wealth of data and descriptions concerning different cas, there remain many unanswered questions about "steering" these systems. In Signals and Boundaries, John Holland argues that understanding the origin of the intricate signal/border hierarchies of these systems is the key to answering such questions. He develops an overarching framework for comparing and steering cas through the mechanisms that generate their signal/boundary hierarchies.Holland lays out a path for developing the framework that emphasizes agents, niches, theory, and mathematical models. He discusses, among other topics, theory construction; signal-processing agents; networks as representations of signal/boundary interaction; adaptation; recombination and reproduction; the use of tagged urn models (adapted from elementary probability theory) to represent boundary hierarchies; finitely generated systems as a way to tie the models examined into a single framework; the framework itself, illustrated by a simple finitely generated version of the development of a multi-celled organism; and Markov processes.},
author = {Holland, J. H.},
isbn = {0262017830},
pages = {308},
publisher = {MIT Press},
title = {{Signals and Boundaries: Building Blocks for Complex Adaptive Systems}},
url = {https://books.google.com/books?id=1BZ9iJbdNV0C\&pgis=1},
year = {2012}
}
@book{Holland2000,
abstract = {'He's the man who taught computers how to have sex. And now, for an encore, he's working on a theory to explain the complexity of life and its myriad manifestations on planet earth.' New York Times In this book, one of today's most innovative thinkers, John H. Holland, explains the theory of emergence-a simple theory that the whole is greater than the sum of its parts. Emergence demonstrates that a small number of rules or laws can generate incredibly complex systems. From thecheckers-playing computer that learnt to beat its creator again and again, to a fertilized egg that can program the development of a trillion-cell organism, to the ant colonies that build bridges over chasms and navigate leaf-boats on streams, this fascinating and groundbreaking book containswide-ranging implications for science, business, and the arts. 'John Holland is an exceptionally imaginative person. Often surprising, and always engaging, he takes the reader on a journey from simplicity to complexity' Sir Robert May},
author = {Holland, J. H.},
isbn = {0192862111},
pages = {258},
publisher = {Oxford University Press},
title = {{Emergence: From Chaos to Order}},
url = {https://books.google.com/books?hl=en\&lr=\&id=VjKtpujRGuAC\&pgis=1},
year = {2000}
}
@book{Holland1995,
abstract = {The father of the field of genetic algorithms, and one of the pioneers of the new science of complexity, Holland has been at the center of the emerging field of complex adaptive systems (cas) since its inception. This landmark book offers for the first time a coherent synthesis of this nascent discipline, a summing up which carries on every page the weight of Holland's authority and distinctive point of view. This book emphasizes the search for general principles that govern cas behavior, enlarging on the intuitions of a broad spectrum of scientists, and it includes a computer model that applies to the full range of cas. Holland concludes with a description of what we might do to enhance our theoretical understanding of cas. He suggests ways in which theory can provide useful guidelines for attacking the perplexing cas problems that stretch our resources and place our world in jeopardy.},
author = {Holland, J. H.},
isbn = {0201442302},
pages = {185},
publisher = {Perseus Books},
title = {{Hidden Order: How Adaptation Builds Complexity}},
url = {https://books.google.com/books?hl=en\&lr=\&id=3eDOuA5pHDoC\&pgis=1},
year = {1995}
}
@incollection{Holland1999,
author = {Holland, J. H.},
booktitle = {Complexity: Metaphors, Models, and Reality},
editor = {Cowen, G. A. and Pines, D. and Meltzer, D.},
isbn = {0-7382-0232-0},
month = nov,
pages = {309--342},
publisher = {Perseus Books},
title = {{Echoing emergence: Objectives, rough definitions, and speculations for ECHO-class models}},
url = {http://dl.acm.org/citation.cfm?id=336600.336652},
year = {1999}
}
@article{Holland1992,
author = {Holland, J. H.},
journal = {Scientific American},
number = {1},
pages = {44--50},
title = {{Genetic algorithms}},
volume = {267},
year = {1992}
}
@book{Holland1989,
abstract = {Two psychologists, a computer scientist, and a philosopher have collaborated to present a framework for understanding processes of inductive reasoning and learning in organisms and machines. Theirs is the first major effort to bring the ideas of several disciplines to bear on a subject that has been a topic of investigation since the time of Socrates. The result is an integrated account that treats problem solving and induction in terms of rule­based mental models. Induction is included in the Computational Models of Cognition and Perception Series. A Bradford Book.},
author = {J.~H. Holland and K.~J. Holyoak and R.~E. Nisbett and P.~R. Thagard},
isbn = {0262580969},
pages = {398},
publisher = {MIT Press},
title = {{Induction: Processes of Inference, Learning, and Discovery}},
url = {https://books.google.com/books?hl=en\&lr=\&id=Z6EFBaLApE8C\&pgis=1},
year = {1989}
}
@article{Holland1986,
author = {Holland, J. H.},
journal = {Machine Learning},
pages = {593 -- 623},
title = {{Escaping brittleness: The possibilities of general purpose learning algorithms applied to parallel rule-based systems}},
volume = {2},
year = {1986}
}
@book{Holland1975,
abstract = {Genetic algorithms are playing an increasingly important role in studies of complex adaptive systems, ranging from adaptive agents in economic theory to the use of machine learning techniques in the design of complex devices such as aircraft turbines and integrated circuits.},
author = {Holland, J. H.},
isbn = {0585038449},
publisher = {University of Michigan Press},
title = {{Adaptation in Natural and Artificial Systems: An Introductory Analysis with Applications to Biology, Control, and Artificial Intelligence}},
url = {https://books.google.com/books?id=cyV7nQEACAAJ\&pgis=1},
year = {1975}
}
@article{Holland1973,
abstract = {This study gives a formal setting to the difficult optimization problems characterized by the conjunction of (1) substantial complexity and initial uncertainty, (2) the necessity of acquiring new information rapidly to reduce the uncertainty, and (3) a requirement that the new information be exploited as acquired so that average performance increases at a rate consistent with the rate of acquisition of information. The setting has as its basis a set \$\backslash mathcal\{A\}\$ of structures to be searched or tried and a performance function \$\backslash mu :\backslash mathcal\{A\} \backslash to \$ real numbers. Within this setting it is determined how to allocate trials to a set of random variables so as to maximize expected performance. This result is then transformed into a criterion against which to measure the performance of a robust and easily implemented set of algorithms called reproductive plans. It is shown that reproductive plans can in fact surpass the criterion because of a phenomenon called intrinsic parallelism—a single trial (individual ...},
author = {Holland, J. H.},
isbn = {10.1137/0202009},
journal = {SIAM Journal on Computing},
language = {en},
month = jul,
number = {2},
pages = {88--105},
publisher = {Society for Industrial and Applied Mathematics},
title = {{Genetic algorithms and the optimal allocation of trials}},
url = {http://epubs.siam.org/doi/abs/10.1137/0202009},
volume = {2},
year = {1973}
}
@article{Holland1962,
author = {Holland, J. H.},
doi = {10.1145/321127.321128},
file = {:Users/mm/Library/Application Support/Mendeley Desktop/Downloaded/Holland - 1962 - Outline for a Logical Theory of Adaptive Systems.pdf:pdf},
issn = {00045411},
journal = {Journal of the ACM},
month = jul,
number = {3},
pages = {297--314},
publisher = {ACM},
title = {{Outline for a logical theory of adaptive systems}},
url = {http://dl.acm.org/citation.cfm?id=321127.321128},
volume = {9},
year = {1962}
}
@article{Holland1977,
author = {Holland, J. H. and Reitman, J. S.},
doi = {10.1145/1045343.1045373},
issn = {01635719},
journal = {ACM SIGART Bulletin},
month = jun,
number = {63},
pages = {49},
publisher = {ACM},
title = {{Cognitive systems based on adaptive algorithms}},
url = {http://dl.acm.org/citation.cfm?id=1045343.1045373},
year = {1977}
}
@article{Hraber1997,
abstract = {Echo is a generic ecosystem model in which evolving agents are situated in a resource-limited environment. The Echo model is described, and the behavior of Echo is evaluated on two well-studied measures of ecological diversity: relative species abundance and the species-area scaling relation. In simulation experiments, these measures are used to compare the behavior of Echo with that of a neutral model, in which selection on agent genotypes is random. These simulations show that the evolutionary component of Echo makes a significant contribution to its behavior and that Echo shows good qualitative agreement with naturally occurring species abundance distributions and species-area scaling relations.},
author = {Hraber, P. T. and Jones, T. and Forrest, S.},
doi = {10.1162/artl.1997.3.3.165},
issn = {1064-5462},
journal = {Artificial Life},
keywords = {Echo,community ecology,genetic algorithms,neutral model,species diversity},
language = {en},
month = jan,
number = {3},
pages = {165--190},
title = {{The ecology of ECHO}},
url = {http://www.mitpressjournals.org/doi/abs/10.1162/artl.1997.3.3.165\#.Vjef9aIzW24},
volume = {3},
year = {1997}
}
@article{Palmer1994,
abstract = {We describe a model of a stockmarket in which independent adaptive agents can buy and sell stock on a central market. The overall market behavior, such as the stock price time series, is an emergent property of the agents' behavior. This approach to modelling a market is contrasted with conventional rational expectations approaches. Our model does not necessarily converge to an equilibrium, and can show bubbles, crashes, and continued high trading volume.},
author = {Palmer, R. G. and Arthur, W. B. and Holland, J. H. and LeBaron, B. and Tayler, P.},
doi = {10.1016/0167-2789(94)90287-9},
file = {:Users/mm/Library/Application Support/Mendeley Desktop/Downloaded/Palmer et al. - 1994 - Artificial economic life a simple model of a stockmarket.pdf:pdf},
issn = {01672789},
journal = {Physica D: Nonlinear Phenomena},
month = aug,
number = {1-3},
pages = {264--274},
title = {{Artificial economic life: A simple model of a stockmarket}},
url = {http://www.sciencedirect.com/science/article/pii/0167278994902879},
volume = {75},
year = {1994}
}
@article{Rochester1956,
abstract = {Theories by D.O. Hebb and P.M. Milner on how the brain works were tested by simulating neuron nets on the IBM Type 704 Electronic Calculator. The formation of cell assemblies from an unorganized net of neurons was demonstrated, as well as a plausible mechanism for short-term memory and the phenomena of growth and fractionation of cell assemblies. The cell assemblies do not yet act just as the theory requires, but changes in the theory and the simulation offer promise for further experimentation.},
author = {Rochester, N. and Holland, J. H. and Haibt, L. H. and Duda, W.},
doi = {10.1109/TIT.1956.1056810},
issn = {0018-9448},
journal = {IEEE Transactions on Information Theory},
keywords = {Assembly,Brain,Brain modeling,Computational modeling,Electronic equipment testing,Fractionation,Laboratories,Neural networks,Neurons,Neurophysiology,Organisms,Psychology},
month = sep,
number = {3},
pages = {80--93},
shorttitle = {Information Theory, IRE Transactions on},
title = {{Tests on a cell assembly theory of the action of the brain, using a large digital computer}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=1056810},
volume = {2},
year = {1956}
}
@article{Samuel1959,
author = {Samuel, A. L.},
doi = {10.1147/rd.33.0210},
issn = {0018-8646},
journal = {IBM Journal of Research and Development},
language = {English},
month = jul,
number = {3},
pages = {210--229},
publisher = {IBM},
title = {{Some studies in machine learning using the game of checkers}},
url = {http://ieeexplore.ieee.org/articleDetails.jsp?arnumber=5392560},
volume = {3},
year = {1959}
}
@book{Shiflet2014,
abstract = {Computational science is an exciting new field at the intersection of the sciences, computer science, and mathematics because much scientific investigation now involves computing as well as theory and experiment. This textbook provides students with a versatile and accessible introduction to the subject. It assumes only a background in high school algebra, enables instructors to follow tailored pathways through the material, and is the only textbook of its kind designed specifically for an introductory course in the computational science and engineering curriculum. While the text itself is generic, an accompanying website offers tutorials and files in a variety of software packages.This fully updated and expanded edition features two new chapters on agent-based simulations and modeling with matrices, ten new project modules, and an additional module on diffusion. Besides increased treatment of high-performance computing and its applications, the book also includes additional quick review questions with answers, exercises, and individual and team projects.The only introductory textbook of its kind—now fully updated and expandedFeatures two new chapters on agent-based simulations and modeling with matricesIncreased coverage of high-performance computing and its applicationsIncludes additional modules, review questions, exercises, and projectsAn online instructor’s manual with exercise answers, selected project solutions, and a test bank and solutions (available only to professors)An online illustration package is available to professors},
author = {Shiflet, A. B. and Shiflet, G. W.},
isbn = {140085055X},
pages = {856},
publisher = {Princeton University Press},
title = {{Introduction to Computational Science: Modeling and Simulation for the Sciences}},
url = {https://books.google.com/books?hl=en\&lr=\&id=UZApAgAAQBAJ\&pgis=1},
year = {2014}
}
@phdthesis{Smith1980,
author = {Smith, S. F.},
month = jan,
publisher = {University of Pittsburgh},
school = {University of Pittsburgh},
title = {{A Learning System Based on Genetic Adaptive Algorithms}},
url = {http://dl.acm.org/citation.cfm?id=909835},
year = {1980}
}
@book{Waldrop1993,
abstract = {In a rented convent in Santa Fe, a revolution has been brewing. The activists are not anarchists, but rather Nobel Laureates in physics and economics such as Murray Gell-Mann and Kenneth Arrow, and pony-tailed graduate students, mathematicians, and computer scientists down from Los Alamos. They've formed an iconoclastic think tank called the Santa Fe Institute, and their radical idea is to create a new science called complexity. These mavericks from academe share a deep impatience with the kind of linear, reductionist thinking that has dominated science since the time of Newton. Instead, they are gathering novel ideas about interconnectedness, coevolution, chaos, structure, and order - and they're forging them into an entirely new, unified way of thinking about nature, human social behavior, life, and the universe itself. They want to know how a primordial soup of simple molecules managed to turn itself into the first living cell - and what the origin of life some four billion years ago can tell us about the process of technological innovation today. They want to know why ancient ecosystems often remained stable for millions of years, only to vanish in a geological instant - and what such events have to do with the sudden collapse of Soviet communism in the late 1980s. They want to know why the economy can behave in unpredictable ways that economists can't explain - and how the random process of Darwinian natural selection managed to produce such wonderfully intricate structures as the eye and the kidney. Above all, they want to know how the universe manages to bring forth complex structures such as galaxies, stars, planets, bacteria, plants, animals, and brains. There are commonthreads in all of these queries, and these Santa Fe scientists seek to understand them. Complexity is their story: the messy, funny, human story of how science really happens. Here is the tale of Brian Arthur, the Belfast-born economist who stubbornly pushed his theories of economic ch},
author = {Waldrop, M. M.},
isbn = {0671872346},
publisher = {Simon and Schuster},
title = {{Complexity: The Emerging Science at the Edge of Order and Chaos}},
url = {https://books.google.com/books?hl=en\&lr=\&id=VP9TWZtVvq8C\&pgis=1},
year = {1993}
}
@book{Ziegler1976,
address = {New York},
author = {Ziegler, B.},
publisher = {Wiley Interscience},
title = {{Theory of Modeling and Simulation}},
year = {1976}
}


@Misc{London2003,
  url = {http://cacm.acm.org/blogs/blog-cacm/159591-who-earned-first-computer-science-phd/fulltext},
  author = 	 {R. L. London},
  title = 	 {Who Earned First Computer Science {Ph.D.}?},
  howpublished = {CACM Blog Post},
  month = 	 {January 15},
  year = 	 2013}


@Article{SuttonAndBarto1990,
  author = 	 {R.~S. Sutton and A.~G. Barto},
  title = 	 {Time Derivative Models of {P}avlovian Reinforcement},
  journal = 	 {Learning and Computational Neuroscience: Foundations of Adaptive Networks},
  year = 	 1990,
  pages = 	 {497--537}}


