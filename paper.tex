\documentclass{sig-alternate}
\usepackage{color}

\newcommand{\red}[1]{\textcolor{red}{#1}}

%\title{Adaptation Writ Large:\\ An Essay in Memory of John H. Holland}

\title{Adaptative Computation:\\ An Essay in Memory of John
  H. Holland}

\numberofauthors{2}
\author 
{\alignauthor
 Stephanie Forrest\\
 \affaddr{University of New Mexico}\\
 \affaddr{Santa Fe Institute}\\
 \email{forrest@cs.unm.edu}
 \alignauthor
Melanie Mitchell \\
 \affaddr{Portland State University}\\
 \affaddr{Santa Fe Institute}\\
 \email{mm@pdx.edu}
}

\begin{document}
\maketitle

\begin{abstract}
This essay reviews the work and influence of the late John H. Holland,
pioneer in the fields of evolutionary computation, machine learning,
and complex systems.  While best known for his invention of
\emph{genetic algorithms}, Holland's scientific motivation was much
broader:  to develop a general theory of adaptation in complex
systems.  We survey Holland's motivation and research with respect to
four central themes, describing his broad and deep influence on modern approaches to computer science and complex systems science.  
\end{abstract}

\section{Introduction}

In August 2015, Professor John H. Holland passed away in Ann Arbor, MI, where
he had served on the University of Michigan faculty for over 50 years.
John, as he was known universally to his colleagues and students,
leaves behind a long legacy of intellectual achievements.

As a descendant of the cybernetics era, Holland was 
influenced by the work of von Neumann, Wiener, Ashby, and Turing, all
of whom viewed computation as a broad, interdisciplinary enterprise.
Thus, Holland became an early proponent of interdisciplinary
approaches to computer science and an active evangelist of what is now
called \emph{computational thinking}, reaching out enthusiastically to
psychologists, economists, physicists, linguists, philosophers, and
pretty much anyone he came in contact with.  As a result, even though
he received what was arguably one of the world's first computer
science
% SF softened the claim here after reading the comments section on the blog.
Ph.D. degrees in 1959 \cite{London2003}, his contributions are sometimes better known outside of
computer science than within.

Holland is best known for his invention of \emph{genetic
  algorithms} (GAs), a family of search and optimization methods inspired
by biological evolution.  Since their invention in the 1960s, GAs have
inspired many related methods and led to the thriving subfield of
\emph{evolutionary computation}, with widespread scientific and
commercial applications.  Although the mechanisms of GAs are well-known,
they were only one
offshoot of Holland's broader motivation---to develop a general
theory of adaptation in complex systems.  

In this short essay, we consider this larger framework, sketching the
recurring themes that were central to Holland's theory of
adaptive systems: (1) discovery and 
dynamics in adaptive search; (2) internal models and prediction; (3) 
exploratory modeling; and (4) universal properties of complex adaptive systems.  

\section{Discovery and Dynamics in Adaptive Search} 

Holland's goal of developing a general theory of adaptation was
spurred both by his early work on computer models of Hebbian learning
\cite{Rochester1956} and his reading of Ronald Fisher's classic book
on integrating genetics with Darwinian selection \cite{Fisher1930}.
As Holland read further in evolutionary biology,
economics, game theory, and control theory, he recognized that
adaptation is central to all these fields.  That is,
these fields all concern populations of agents that must continually
obtain information from uncertain, changing environments and use it 
to improve performance and enhance the chance of survival. 

Holland also recognized that adaptation must be a continual
open-ended process due to perpetually uncertain and changing
environments.  In his view, adaptive systems never achieve a state of
equilibrium or a final optimum configuration.  This emphasis on
open-ended, non-equilibrium dynamics was in stark contrast with the
mainstream approach (at the time) in all these fields---the belief
that solving for stable equilibrium dynamics was the scientific goal.
Holland's contrary view was that a system in stable equilibrium is
essentially \emph{dead}.

Underlying Holland's theory of adaptation are the following core ideas:  

\begin{itemize}
\item{\bf Populations, sampling, and implicit parallelism:} 
  Evolution is a form of search that leverages statistics to
  direct population dynamics.  Initially, the population is an 
 independent sample of many individuals (from the space of all possible
  individuals), and over time the sample is increasingly biased
  towards the high-fitness regions of the search space.  In addition,
the population can be viewed as an
  implicit sample of the much larger space of \emph{traits} that
  comprise those individuals.  Holland termed this implicit
  large-scale sampling of traits ``implicit parallelism.''
  Evolutionary dynamics biases these samples over time towards
  high-fitness regions of the search space.

\item{\bf Building blocks and recombination:} 
  In a population undergoing adaptation,
  individuals can be decomposed into \emph{building blocks}---sets of
  traits that are the evolutionary ``atoms'' of an individual's
  fitness or performance. (As an example from biology, Holland often mentioned
  the \emph{Krebs cycle}, a core cellular metabolic
  pathway that is highly conserved across living systems.)   Successful individuals
  are discovered in stages, first by finding useful
  building blocks through stochastic sampling, and over
  time recombining them to create higher-fitness individuals out of
  more complex building blocks.

%  For example, when searching the space of
%  all $n$-bit binary strings, almost any random sample would contain
%  examples of strings whose first bit is set to 1, and also many
%  samples of strings whose second bit is set to 1, but there would be
%  many fewer samples that have both of the first two bits set to
%  1.  More compelling examples include the \emph{Krebs cycle}, a core
%  cellular metabolic pathway, 

%  To succeed, such a search requires first that
%  useful building blocks be preserved once discovered, and second that
%  there be an efficient mechanism for combining promising building
%  blocks into higher-order building blocks.  Holland proposed using an
%  analog of Darwinian selection for the first and the idea of crossing
%  over in genetics for the second.  Holland referred to the building
%  blocks as \emph{schemas} and defined them as hyperplanes in the search space. 

%In a population undergoing adaptation,
%  individuals can be decomposed into \emph{building blocks}---sets of
% traits that are the evolutionary ``atoms'' of an individual's
%  fitness or performance. 

\item{\bf Exploitation Versus Exploration:} Successful adaptation
  requires maintaining a balance between \emph{exploitation}, in which
  successful building blocks propagate in a population, and
  \emph{exploration}, in which existing building blocks are recombined
  or mutated in new ways.

\end{itemize} 

Inspired by Bellman \cite{Bellman1961} and
others, Holland formalized the exploitation-versus-exploration tradeoff
as an idealized ``two-armed bandit'' problem. Given a slot machine
with two arms, each of which has an unknown payoff probability, how
should you allocate trials (pulls) between the arms so as to
maximize your total payoff?   In \cite{Holland1973,Holland1975}
Holland argued that the optimal strategy
allocates trials to the observed best arm at a slightly higher rate than
an exponential function of the trials allocated to the observed worse arm.  

Next, Holland showed that in populations undergoing adaptation,
building blocks are analogous to arms on a multi-armed bandit.  
%Thus,
%in the process of assigning a fitness to each individual in a
%population, adaptive evolution can be seen as implicitly sampling the
%many building blocks making up that collection of individuals.
Evaluating an individual in an environment is analogous to pulling selected
arms on a multi-armed bandit, where the arms correspond to each of the
building blocks making up that individual.

The question of balancing exploitation and exploration---how to
optimally allocate trials to different arms based on their observed 
payoffs---now becomes the question of how to optimally sample in the
vast space of possible building blocks, based on their estimated
contribution to fitness.  Of course, evolution deals in populations of
individuals, not building blocks.  There is no \emph{explicit} mechanism that
keeps statistics on how building blocks contribute to fitness. 
Holland's central idea here is that an approximation to
optimal building-block sampling occurs implicitly, as an emergent
property of evolutionary population dynamics.

Several of Holland's early papers (e.g.,
\cite{Holland1962,Holland1973}) and his influential 1975 book
\emph{Adaptation in Natural and Artificial Systems} \cite{Holland1975}
developed a general, formal setting in which these ideas could be
expressed mathematically.  It was this formalization that led to the
invention of genetic algorithms, which featured stochastic
population-based search, as well as crossover between individuals as a
critical operation that allows successful building blocks to be
recombined and tested in new contexts.  

% Reviewer 3: I'd be careful with anything relating to the building block hypothesis (that recombination is successful by combining building blocks). How recombination really works and what it serves to seems to be little understood both in genetic algorithms and in biology. In the genetic algorithms literature, there is at least as many negative evidence for the building block hypothesis as support, including a well-known paper by the authors.

Holland's aim, however, was more general than a new class of algorithms.  His goal was an
interdisciplinary theory of adaptation, one that would inform biology, 
say, as much as computer science \cite{Christiansen1998}.  The later, successful application of
genetic algorithms to real-world optimization and learning tasks was,
for Holland, just icing on the cake.  
Holland's broader view of adaptation
has inspired many, and engendered criticism
from others, leading to spirited intellectual debates and
controversies.  Most controversial is the extent to which it can be
demonstrated, either empirically or mathematically, that the behavior
of adaptive systems is actually governed by Holland's proposed principles.
Regardless of one's position on this question, the ideas are compelling
and provide a set of unifying concepts for thinking about adaptation.
%as follows:
%Underlying Holland's theory of adaptation are the following core ideas:  


%What made GAs unique
%among other evolution-inspired algorithms at the time were the
%mathematical foundations described above, the emphasis on populations
%and recombination as central mechanisms,
%and a focus 
%(at least in Holland's mind) [MM SAYS: THIS SOUNDS TOO NEGATIVE]
%on continual adaptation in
%non-stationary environments rather than optimization in static
%environments.

%The later, successful application of
%genetic algorithms to real-world optimization and learning tasks was,
%for Holland, just icing on the cake.
% SF liked 'icing on the cake.'

%What made GAs unique
%among other evolution-inspired algorithms at the time were the
%mathematical foundations described above, the emphasis on populations
%and recombination as central mechanisms,
%and a focus 
%(at least in Holland's mind) [MM SAYS: THIS SOUNDS TOO NEGATIVE]
%on continual adaptation in
%non-stationary environments rather than optimization in static
%environments.



%\section{Internal Models and Perpetual Novelty}
\section{Internal Models and Prediction}

%One system of special interest to Holland was the human mind, and in
%particular, its capacity to learn via induction.

Internal models are central to Holland's theory of adaptive systems.
He posits that all adaptive systems create and use internal models to
prosper in the face of ``perpetual novelty.'' 

Models can be tacit and learned over evolutionary time, as in the
case of bacteria swimming up a chemical gradient, or explicit and
learned over a single lifespan, as in the case of cognitive systems
that incorporate experience into internal representations through
learning.  In Holland's view, the key activity of an adaptive agent
involves building and refining these data-driven models of the
environment.

In his second book, \emph{Induction} \cite{Holland1989}, Holland and
his co-authors proposed inductive methods by which cognitive agents
can construct---and profit from---internal models by combining
environmental inputs and rewards with stored knowledge.  In their
framework, a model defines a set of equivalence relations---a
homomorphism---over environmental states, together with a set of
transition rules which are learned over time based on environmental
rewards (or punishments).  Models that form valid homomorphisms with
the environment allow the system to make accurate predictions.  In
Holland's conception, the equivalence classes are initially very
general, for example, ``moving object'' and ``stationary object.''
Through experience and learning, these can be specialized into more
useful and precise subclasses, say ``insect'' and ``nest.''  Over
time, the adaptive system builds up a default hierarchy of rules
covering general cases and refinements for specific classes.

Although the idea of default hierarchies was prevalent in knowledge
representation systems of the era, Holland made two key contributions.
The first was his emphasis on homomorphisms as a formal way to
evaluate model validity, an idea that dates back to Ross Ashby's
\emph{An Introduction to Cybernetics} \cite{Ashby1956}. Holland's
student Bernard Ziegler developed this idea into a formal theory of
computer modeling and simulation \cite{Ziegler1976}.  Even today,
these early homomorphic theories of modeling stand as the most elegant
approach we know of to characterize when a model is consistent with
the environment and how an intelligent agent, human or artificial, can
update a model to better reflect reality.

Holland's second key contribution was describing a computational
mechanism, the \emph{learning classifier
  system}~\cite{Holland1986,Holland1977}, to illustrate how a cognitive system could
iteratively build up a detailed and hierarchical model of its
environment to enhance survival.  The key learning elements of this method, the
bucket-brigade algorithm, combined with a genetic algorithm, presaged many of the ideas in modern reinforcement
learning, notably the temporal-difference methods introduced by
Sutton and Barto~\cite{SuttonAndBarto1990}.

%Offspring rules, which begin life weaker than do their parents, can
%win the competition and influence the system's behavior only when
%there are not strong rules whose conditions are satisfied---in other
%words when the system does not know what to do.  If their actions
%help, they survive; if not they are soon replaced.  
%Thus,


%including unsupervised learning, non-Markovian learning, AND
%ONE OTHER?.

% While genetic algorithms are nowadays most often associated with models of
% biological evolution, in Holland's view the processes of adaptation he
% was studying manifested themselves in many different complex systems.

% In the 1970s and 80s Holland formulated and extensively explored a
% particular model of decision-making, action, and inductive learning,
% called the \emph{classifier system} (e.g.,)
% .  In a classifier system, a population
% of ``if-then'' rules interacts with an environment, and over time is
% able to learn to improve its performance via both \emph{
%   credit-assignment} and \emph{rule-discovery} algorithms.

% Like genetic algorithms, classifier systems can be viewed both as 
% models of adaptation and as artificial-intelligence (AI) methods.  At
% the time Holland was developing classifier systems, the field of AI
% was focused on expert systems, which typically did not learn on their
% own, a fundamental deficiency in Holland's view: ``[Expert] systems
% are brittle in the sense that they respond appropriately only in
% narrow domains, requiring substantial human intervention to compensate
% for even slight shifts in domain'' \cite{Holland1986}. In
% contrast, Holland proposed that ``\emph{induction} is the basic, and
% perhaps only, way of making large advances in this direction.''

Holland's inspiration for classifier systems came from several
different disciplines, including Hebbian
learning, artificial intelligence, evolutionary biology, economics,
psychology, and control theory.
% MM says: We cite these elsewhere in the paper
%(e.g.,\cite{Bellman1961,Samuel1959}).  
Knowledge representation in the form of a population of ``if-then''
rules seemed like a good choice, not only because of its popularity in
AI at the time but also from Holland's early work on modeling Hebbian
cell assemblies: ``In Hebb's view, a cell assembly makes a simple
statement: If such and such an event occurs, then I will fire for a
while at a high rate'' \cite{Waldrop1993}.  The if-then rules, when
activated, compete to post their results on a shared ``message list,''
serving as the system's short-term memory, again inspired by Hebb's
work as well as by AI blackboard systems of the day.  Unlike blackboard
systems, however, new rules are generated automatically in a
trial-and-error fashion, and can be selected and recombined via a
genetic algorithm.

Successful rules are strengthened over time if their predictions led
to positive rewards from the environment (and weakened otherwise)
through a credit-assignment method called the \emph{bucket-brigade}
algorithm, in which rules gaining rewards from the environment, or from
other rules, transfer some of their gains to earlier-firing
``stage-setting'' rules that set up the conditions for the eventual
reward. Holland credited Arthur Samuel's pioneering work on machine
learning applied to checkers \cite{Samuel1959} as a key inspiration for these ideas.

Holland was primarily interested in how the two
learning mechanisms (discovery of new rules and apportioning credit to
existing rules) could work together to create 
%subsets of rules
%that accurately model the environment, and thus are able to ``fire''
%at appropriate times.  
%Holland envisioned that, with a complex environment and enough time
%for learning, a classifier system might learn an intricate default
useful default hierarchies of rules.  He emphasized that the
competition inherent in the learning and action mechanisms would allow
the system to adapt to a continually changing environment without
losing what it had learned in the past.  Holland put it this way:
``Competition among rules provides the system with a graceful way of
handling perpetual novelty.  When a system has strong rules that
respond to a particular situation, that is the equivalent of saying
that it has certain well-validated hypotheses.... New rules do not
interfere with the system's action in well-practiced situations but
wait gracefully in the wings as hypotheses about what to do under
novel circumstances.'' \cite{Holland1992}.

%Finally, new rules for the population are discovered by a genetic
%algorithm, using the strength of rules as a fitness function.
%Classifier systems are fairly complex architectures, with learning
%occurring at multiple time scales.  
Although Holland proposed classifier systems as 
an executable theory of inductive processes in cognition, other researchers took it further, 
%other researchers took the
%computational system more seriously
applying it to areas as diverse as poker-playing \cite{Smith1980},
control of gas pipeline transmission \cite{Goldberg1983}, and modeling
the stock market \cite{Palmer1994}.  (See Ref.~\cite{Booker1989} for
more details about practical applications of classifier systems.)
Today, other reinforcement learning methods are more popular for
real-world decision and control problems, but classifier systems can
perhaps be thought of as an early stage-setting method that
foreshadowed these later approaches.

% \footnote{Of course similar
%   credit-assignment methods have been used extensively in
%   reinforcement learning, neural networks, and other areas of modern
%   machine learning, but Holland was among the first to propose such
%   methods.}

\section{Exploratory Modeling}

Given that Holland believed that the ability to learn and manipulate
internal models was essential for any adaptive system, it is no
surprise that he viewed modeling as essential for scientific inquiry.

%Today, we use computational models in several distinct ways---as
%tools for analyzing data in statistical models; as methods for
%discovering new knowledge; and as a means to understand how complex
%systems works.  [Steph, I am not clear on the distinction between the
%second and third things here, so I combined them.  Change back if you
%want.]

Today, we use computational models both for \emph{prediction}---by
analyzing data via statistical models---and for \emph{understanding}
how systems work---by probing the effects of hypothesized underlying
mechanisms.  This latter use of models was dear to Holland's heart.
In his view, the key to science was understanding the mechanisms that
cause a system to behave in a certain way, an aspiration that goes
well beyond data-fitting methods, which typically focus only on
the aggregate behavior of a system.  

For example, a purely statistical model that describes the boom and bust
pattern of the stock market
%cannot
does not address the underlying mechanisms
that lead to these cycles, through the collective actions of myriad
individual buy/sell decisions.  
%Similarly
In contrast, the genetic algorithms for which Holland is so famous
are exploratory models of \emph{mechanism}: they provide a simple
computational framework in which to explore the dynamics of Darwinian
evolution and whether the basic mechanisms of variation, differential
reproduction, and heredity are sufficient to account for the richness
of the natural world.

Holland's work focused on \emph{exploratory} models---those that explore basic principles and
mechanisms, even if they do not make specific or detailed
predictions \cite{Holland1995}.  Such models can show generically how certain behaviors
could be produced.  Holland pioneered a style of modeling that has
come to be known as ``individual-based'' or ``agent-based,'' in which
every component of a system is represented explicitly---e.g., every
trader in a stock market system or every cell in an immune system
model---and has a dynamic internal state. In such models, each agent has
its own behavior rules, which it can modify over time through learning.  In
order to capture the behavior of systems under spatial
constraints, these models are often defined over spatial structures
such as networks or simple grids.

%MM says:  This next sentence not needed. 
%A given agent-based model encodes a theory about the mechanisms that
%are relevant for producing the behavior of interest.  

%Similar to expert systems [MM says: ?]
%Such models are especially useful for studying systems
%that do not have analytic mathematical descriptions.  [MM took out to shorten this paragraph]
%Agent-based models can facilitate interdisciplinary collaborations because the
%underlying rules can be easily communicated.  
%[SF: THINKS this next text doesn't make sense until after complex
%systems seciton.]
The exploratory models championed by Holland were not intended to
provide detailed, domain-specific predictions.  Instead they were
meant to explore possible general mechanisms of complex systems and
thus provide insights that might lead to more specific, detailed
models.  Such idealized models are akin to what philosopher Daniel Dennett has called
``intuition pumps'' \cite{Dennett1984}.

The emphasis on exploratory models to build intuitions was an
important theme of Holland's work, and he often quoted Eddington's
remark on the occasion of the first experimental test of Einstein's
theory of relativity: ``The contemplation in natural science of a wider
domain than the actual leads to a far better understanding of the
actual'' \cite{Eddington1927}.
%Holland's view of modeling was by no means
%typical.  As just one example of the prevailing view that models are
%for predicting: 
%For example, a textbook on computational modeling offers
% the following definition: 
%``Modeling is the application
%of methods to analyze complex, real-world problems in order to make
%predictions about what might happen with various actions''
%\cite{Shiflet2014}.   This perspective rules out the
%kind of exploratory modeling that interested Holland the most. 

% Some researchers dispute that models make any kind of scientific
% contribution: ``Models are metaphors that explain the world we don't
% understand in terms of worlds we do.  They are merely analogies,
% provide partial insight, stand on someone else's feet.  Theories stand
% on their own feet, and rely on no analogies.''  [Emanuel Derman, 2012].
% [MM SAYS:  I COULD NOT FIND REFERENCE FOR THIS QUOTE OUTSIDE SFI VIDEO.]
% [MM SAYS:  Possibly delete this paragraph.]

% [NOW WE NEED A STRONG FINISHING SENTENCE TO RESCUE JHH STYLE
%   MODELING.]

%\section{Common Properties of Complex Adaptive Systems}

\section{Universal Properties of Complex Adaptive Systems}

Holland was interested in a broad array of adaptive systems, such as immune
systems, ecologies, financial markets, cities, and the brain---systems
that are \emph{complex}.  In the early 1980s, he teamed up with a small
group of scientists, primarily physicists, with a sprinkling of
economists and biologists, to discuss what properties this wide swath of systems
have in common.  The discussions helped define the intellectual mission
of the Santa Fe Institute (SFI), the first institution dedicated to
developing a science of complexity, as well as the other complexity institutes that followed.
% [add in how many complexity
%  institutes there are worldwide and which others John played a hand
%  in. MM says: Do we really need that?]  
Holland brought to these discussions his lifelong study of
adaptation and a reminder that serious theories about complexity would
need to look deeper than phenomenological descriptions but also
account for the `how' and `why' of these systems.
%describing phenomena like chaos, power laws, and ONE MORE, and acoount for the  

As the discussions matured, a consensus developed about the basic
elements of complex systems, which are: (1) 
%complex systems are 
composed of many
components with nonlinear interactions; (2) 
%such systems
%are 
characterized by complex \emph{emergent} behavior, exhibiting
higher-order patterns; (3) 
%such systems 
operating at multiple (and often
% interacting? 
nested) spatial and temporal scales, with some behavior 
conserved across all scales and other behaviors changing at different
scales, and (4) 
%these systems exhibit 
adaptive, with 
behavioral rules continually adjusted through evolution and learning.  Although this
is far from a formal definition of complex systems, most people
working in the field today are interested in systems that have these
properties.

%To illustrate his ideas about the ubiquity of adaptation, Holland and
%co-workers developed two exploratory models, the SFI Artificial Stock
%Market and ECHO.  

In the early 1990s, Holland teamed up with other Santa Fe Institute researchers,
including several economists, to tackle the mismatch between predictions
of rational expectations theory (the dominant theory in economics at the time) 
and empirically observed stock market behaviors. 
%that deviated from the predicted equilibrium solutions.  
In brief, most
economic theory of the day assumed that all participants in an economy
or financial market are fully rational, and act to maximize their
individual gain.  In real life, however, actors in economies
and markets are rarely wholly rational, and financial markets often deviate
from rationality, for example with speculative bubbles and crashes.

The SFI Artificial Stock Market project \cite{Arthur1997b,Palmer1994}
developed an exploratory model in which rational
traders were replaced by \emph{adaptive} traders---those who learn to
forecast stock prices over time.  The model tested for the
emergence of different trading strategies, including
\emph{fundamental}, \emph{technical}, or \emph{uninformed}
strategies. The simulated market with adaptive trading agents was run
many times, and the dynamics of price and trading volumes were
compared to observed patterns in real markets.  Holland and his
collaborators found that the model's dynamics replicated several
otherwise puzzling features of real-life markets.

Although the SFI Stock Market model was highly simplified, it was very
influential and led to many follow-on projects.  It 
demonstrated clearly the essential role that adaptation plays in complex
systems, and it illustrated how Holland's theories of continual learning
in response to intermittent feedbacks from the environment could be
integrated into domain-specific settings.

ECHO \cite{Holland1999,Hraber1997} was an even more ambitious exploratory model
that Holland and collaborators developed during the 1990s. 
% ECHO's
% scope included the evolution of interacting populations of individual
% agents, which through competition and learning discover symbiotic
% triads such as the famous ant-fly-caterpillar interaction, the Wiksell
% triangle of trading relationships in economics, and the immune
% system's learned ability to distinguish `self' from `other.'
ECHO formalized Holland's idealization of complex adaptive systems
into a runnable computational system where agents evolved external
markers (called tags) and internal preferences, and then used them to
acquire resources and form higher-level aggregate structures, such as
trading relationships, symbiotic groups, trophic cascades, and
interdependent organizations.  ECHO agents sometimes discovered
mimicry and used it to deceive competitors.  In many runs, the model
developed increasingly complex structures and behaviors. % up to a point.
When these runs stabilized, the resulting population of agents was
found to reproduce several well-known patterns observed in nature,
most famously the rank-frequency distribution of species diversity
known as the Preston curve in ecology.  In layman's terms, ECHO
evolved populations where ``most species are rare.''

The broad scope of the model, together with its ability to produce
easily identifiable and well-known patterns from nature, was appealing
to immunologists, economists, and evolutionary biologists alike.  Many
of the insights behind this project are described in Holland's third
book, \emph{Hidden Order} \cite{Holland1995}.  

% but it
%was the economists who took it one step further in the SFI stock
%market.

%Reviewer 3It seems to me that the essay could stress even more that Holland was interested in "open ended systems" and that,  ironically,   as genetic algorithms were turned into static function optimizers these "next generation evolutionary algorithms" lost the adaptive properties that Holland valued and emphasized.     We still have very little idea about how to build truly open ended systems.


%Blake LeBaron (economics);
% W. Brian Arthur (economics); 
% John Holland (psychology/EE/CS,
% and father of GAs);
% Richard Palmer (physics);
% Paul Taylor (computer science

%Many modeling issues not satisfactorily resolved by the SF-ASM model have been 
% taken up in later research (see Ref.[4]).

Holland's later books, \emph{Emergence} \cite{Holland2000},
\emph{Signals and Boundaries} \cite{Holland2012}, and
\emph{Complexity: A Very Short Introduction} \cite{Holland2014} show how the
theories of adaptation that Holland developed during the earlier part
of his career fit into the larger landscape of complex systems
research.  In these works he especially emphasized the open-ended
nature of complex systems, where change and adaptation are
continual, systems co-evolve with each other, and ecological niches arise
and decay spontaneously depending on resource availability and competition.

%i thnk you left out a major  theme in john: the role of the concept of niche.
 % for example, i think that he  was so interested in flows.  because a niche
% can be thought of as a pattterns of flows.  and ibelfeve -one of his
% major goal  ofor ECHO was to study   niche formation and structure 
% did yolu knolw that af\ef the bach gtoujp  \faded we stArted  A group 
% dedicted to zstudyung nichrd ijn all  thire guiidee, i/with john, nmercdes, 
% scott, mi\\chael cohen ,evan ecnomo (a rackam fcfelw) , and me as the core,
%  wiyth visits by;\mike gordon, bob savitn ]marjk newman maria riolo,ed askerville, etc, 
% as far as i can tell, we ]met on avg about 1/mon from  oct 200 - feb
% 2012.

Holland's focus on understanding the mechanisms by which complex patterns emerge and change,
rather than simply characterizing the patterns themselves (e.g.,
describing chaotic attractors or power laws), reflected his
determination to get to the heart of complex adaptive systems.
This determination represents the best of science.  Holland's
willingness to tackle the hardest questions, develop his own
formalisms, and use mathematics and simulation to provide insight sets a high bar for
scientists in all disciplines.
%to whch we
%all should aspire.

%\section{Relevance to Modern CS}
%[MM says:  Do we need this section?  Or can we incorporate these points within the previous sections?]


\section{Conclusion}

John Holland was unusual in his ability to absorb the essence of other
disciplines, articulate grand overarching
principles, and then back them up with computational mechanisms and
mathematics.  Unlike most researchers, Holland moved seamlessly among these
three modes of thinking, developing models that were years ahead of their time.  A
close reading of his work reveals the antecedents of many ideas prevalent in
machine learning today, e.g., reinforcement, learning in non-Markovian
environments, and active learning.   His seminal genetic algorithm
spawned the field of evolutionary computation, and his insights
and wisdom helped define what are now referred to as the
\emph{sciences of complexity}.   

Holland's many books and articles have influenced scientists around
the world and across many disciplines.  Closer to home, he introduced
several generations of students at the University of Michigan to
computation in natural systems, an idea that even today remains
somewhat controversial, despite successes in genetic algorithms for
engineering design, biomimicry for robotics, abstractions of pheromone
trails in ant colonies for optimization methods, and the use of
mechanisms from immunology to improve computer security.

Behind the ideas, of course, is the man himself.   Everyone who knew
John personally will remember the gleam in his eye when he
encountered a new idea; his willingness to talk to anyone, no matter
how famous or obscure; and his incredible generosity and patience.
%His insights aboutwere deeper and more general than what often passes for work in biomimicry, e.g., for robots.
Holland's personality and humanity were somehow inextricably entangled
with his intellectual contributions.  Since his death, many of
Holland's former students and colleagues have movingly described their
desire to emulate his personal qualities as much as his scientific
excellence.  John Holland's ideas, intellectual passion, and personal approach will serve as
beacons for research in intelligent and complex systems for many
years to come. 
%the world of science is poorer without John
%Holland on the scene.


% \begin{itemize}
% \item Evolutionary computation
% \item Q Learning
% \item Backprop
% \item    From Turing nomination: "Holland's machine learning system known as the
%    Learning Classifier System (LCS), developed in the early 1980s,
%    incorporated a reinforcement learning algorithm known as the bucket
%    brigade for non-Markovian environments, anticipating by nearly a
%    decade non-Markovian learning algorithms."
% \item Exploitation versus exploration -- relevance to reinforcement
%   learning, other parts of machine learning and optimization.
% \item Active learning.  (Two-armed bandit problem.) 
% \item On-line learning.  
% \end{itemize}

\section{Acknowledgments}

The authors thank R. Axelrod, L. Booker, R. Riolo, K. Winter, and the
anonymous reviewers for their careful reading of the manuscript and
many helpful suggestions.  SF gratefully acknowledges the partial
support of NSF (NeTS 1518878, CNS 1444500), DARPA (FA8750-15-C-0118),
Air Force Office of Scientific Research (FA8750-15-2-0075), and the
Santa Fe Institute.  MM gratefully acknowledges the partial support of
NSF (IIS-1423651).  Any opinions, findings, and conclusions or
recommendations expressed in this material are those of the authors
and do not necessarily reflect the views of the National Science
Foundation.

\bibliographystyle{plain}

\bibliography{paper}

\end{document}
